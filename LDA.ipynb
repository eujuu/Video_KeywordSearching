{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GxCYvZbCRV4"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chJHnKUUCiHc"
   },
   "outputs": [],
   "source": [
    "scripts = []\n",
    "with open('/content/drive/My Drive/hana_scripts.txt', 'r') as f:\n",
    "  para = f.readlines()\n",
    "  for line in para:\n",
    "    scripts.append(line.rstrip().lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZuzxgPOCiFd"
   },
   "outputs": [],
   "source": [
    "scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Inm3AZtFrQST"
   },
   "outputs": [],
   "source": [
    "!apt-get update \n",
    "!apt-get install g++ openjdk-8-jdk python-dev python3-dev \n",
    "import os\n",
    "os.environ['JAVA_HOME']=\"C:\\Program Files\\Java\\jdk-14.0.2\"\n",
    "!pip3 install JPype1-py3 \n",
    "!pip3 install konlpy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPLm2SNTDp6u"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "import kss\n",
    "ex_sent = []\n",
    "for sen in scripts:\n",
    "  #for sent in kss.split_sentences(sen):\n",
    "  #  ex_sent.append(sent)\n",
    "  ex_sent.extend(kkma.sentences(sen))\n",
    "ex_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bYEgvRACiCj"
   },
   "outputs": [],
   "source": [
    "\n",
    "tf_vect = TfidfVectorizer( ngram_range = (1, 2 ), min_df = 2, max_df = 20000)\n",
    "dtm = tf_vect.fit_transform(ex_sent)\n",
    "n_topics = 10\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = n_topics)\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOkNjSkjwSX2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "Uu6syjgECh_h",
    "outputId": "703e00b5-2f94-449b-d4e6-d25a2eb1bffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 1: \n",
      "[('여기', 3.98), ('되는', 1.65), ('어제', 1.62), ('있는', 1.61), ('금호', 1.6), ('많이', 1.56), ('제가', 1.31), ('있어', 1.27), ('여러분들', 1.24), ('빨리', 1.23), ('백신', 1.16), ('생각이', 1.13), ('오히려', 1.11), ('보면서', 1.1), ('되는 거예요', 1.08), ('엄청', 1.08), ('되나요', 1.05), ('주지', 1.05), ('같은', 1.04), ('번째', 1.02), ('이래서', 1.02), ('그래서', 1.02), ('거예요', 1.0), ('이렇게', 1.0), ('요런', 0.98), ('하고', 0.95), ('보시면', 0.94), ('그런', 0.94)]\n",
      "topic 2: \n",
      "[('그죠', 47.63), ('한번', 3.85), ('보시면', 2.09), ('그러면', 1.98), ('오늘', 1.87), ('드렸는데', 1.77), ('지금', 1.77), ('그렇게', 1.55), ('그래서', 1.52), ('해서', 1.48), ('때문에', 1.38), ('조심스럽게', 1.32), ('일단은', 1.27), ('정도', 1.26), ('그래', 1.25), ('그런', 1.13), ('에너지가', 1.13), ('여러분들께', 1.12), ('좋아요', 1.1), ('잠깐만', 1.1), ('없잖아요', 1.1), ('저는', 1.09), ('시장에', 1.07), ('모든', 1.06), ('그동안', 1.04), ('여기', 1.03), ('솔루션', 1.02), ('내가', 1.02)]\n",
      "topic 3: \n",
      "[('제가', 3.01), ('분기', 2.36), ('드릴게요', 2.13), ('저는', 2.02), ('분기 실적', 1.98), ('있는', 1.97), ('실적', 1.95), ('지금', 1.91), ('먼저', 1.87), ('임상', 1.52), ('이렇게', 1.52), ('하고', 1.51), ('그러면', 1.43), ('말씀', 1.39), ('여기', 1.39), ('보고', 1.28), ('때문에', 1.25), ('보내', 1.21), ('한번', 1.2), ('다음', 1.19), ('회사가', 1.19), ('우리', 1.18), ('최근에', 1.15), ('이야기해', 1.11), ('기회에', 1.08), ('50', 1.07), ('오늘', 1.06), ('그죠', 1.04)]\n",
      "topic 4: \n",
      "[('때문에', 2.27), ('요거', 2.07), ('하고', 1.74), ('지금', 1.7), ('많이', 1.6), ('저는', 1.4), ('제가', 1.37), ('그래서', 1.33), ('다음에', 1.32), ('여러분들께', 1.28), ('이제', 1.27), ('있잖아', 1.25), ('미국의', 1.23), ('그냥', 1.21), ('이런', 1.18), ('먼저', 1.14), ('행복한', 1.1), ('드렸습니다', 0.98), ('들이', 0.97), ('어제', 0.94), ('있는', 0.94), ('sm', 0.94), ('드린', 0.91), ('그저께', 0.91), ('가지고', 0.9), ('뭐냐', 0.89), ('다이브', 0.87), ('기회가', 0.86)]\n",
      "topic 5: \n",
      "[('그런', 2.93), ('그래서', 1.87), ('지금', 1.71), ('봐야', 1.64), ('이런', 1.61), ('제가', 1.52), ('내가', 1.49), ('봐야 되겠죠', 1.48), ('여러', 1.44), ('되겠죠', 1.43), ('다른', 1.41), ('이제', 1.38), ('분들은', 1.36), ('한번', 1.36), ('하고', 1.35), ('많이', 1.31), ('생각을', 1.28), ('추가적으로', 1.26), ('종목이', 1.19), ('정도', 1.17), ('그다음에', 1.17), ('아니잖아', 1.1), ('잠깐만요', 1.1), ('지를', 1.09), ('드렸던', 1.02), ('미디어', 1.02), ('때문에', 1.0), ('우리', 0.99)]\n",
      "topic 6: \n",
      "[('거죠', 2.52), ('제가', 2.36), ('이렇게', 2.07), ('그렇다고', 1.78), ('jyp', 1.72), ('지금', 1.63), ('최근에', 1.54), ('드릴', 1.42), ('그래서', 1.23), ('혹시', 1.22), ('있는', 1.22), ('언제', 1.19), ('오늘도', 1.19), ('다음에', 1.17), ('어쨌든', 1.16), ('그런', 1.16), ('드리고', 1.16), ('회사들이', 1.1), ('생각입니다', 1.1), ('싶어요', 1.1), ('5시', 1.1), ('반드시', 1.02), ('있죠', 1.01), ('이거', 1.01), ('의학', 1.01), ('보고', 1.01), ('다시', 1.0), ('그러면', 1.0)]\n",
      "topic 7: \n",
      "[('그래서', 3.29), ('이렇게', 2.89), ('근데', 2.48), ('지금', 2.44), ('일단', 2.34), ('한번', 2.01), ('전화', 1.91), ('제가', 1.88), ('이제', 1.44), ('오늘', 1.37), ('내가', 1.19), ('어떤', 1.17), ('그래서 일단', 1.17), ('나오는', 1.12), ('여러분들도', 1.1), ('아직', 1.08), ('봤을 때는', 1.07), ('봤을', 1.07), ('제가 봤을', 1.07), ('때는', 1.01), ('기본적으로', 0.96), ('시가', 0.96), ('기관들이', 0.95), ('최근에', 0.94), ('이런', 0.93), ('사이트가', 0.91), ('들을', 0.9), ('있어서', 0.88)]\n",
      "topic 8: \n",
      "[('이제', 3.6), ('정도', 2.62), ('올래', 2.1), ('제가', 1.94), ('한번', 1.9), ('절반', 1.53), ('그래서', 1.51), ('조금', 1.45), ('고요', 1.43), ('않을까', 1.43), ('이게', 1.42), ('이렇게', 1.41), ('테크', 1.4), ('그렇게', 1.36), ('이거', 1.32), ('여러분들께', 1.28), ('여기', 1.26), ('7천', 1.24), ('그러면', 1.21), ('하고', 1.15), ('여기서', 1.14), ('좋은', 1.1), ('근데', 1.07), ('너무', 1.07), ('지금', 1.04), ('고점에서', 1.01), ('식사', 0.99), ('맛있게', 0.99)]\n",
      "topic 9: \n",
      "[('제가', 4.01), ('많이', 2.33), ('가지고', 2.13), ('이거', 1.92), ('아니야', 1.7), ('우리', 1.59), ('그때', 1.53), ('여러분들께', 1.52), ('이상', 1.39), ('있을', 1.38), ('여기잖아', 1.38), ('제가 여러분들께', 1.36), ('그래서', 1.35), ('만약에', 1.35), ('지금', 1.34), ('얼마나', 1.33), ('다이버', 1.31), ('정도', 1.29), ('kmw', 1.2), ('된다', 1.19), ('봐야', 1.16), ('뭐라고', 1.14), ('이야기를', 1.11), ('그럼', 1.09), ('있잖아', 1.08), ('상승', 1.08), ('완벽하게', 1.04), ('오늘', 1.03)]\n",
      "topic 10: \n",
      "[('폴리텍', 2.41), ('때문에', 1.87), ('cis', 1.84), ('않습니다', 1.78), ('그렇게', 1.63), ('있습니다', 1.58), ('제가', 1.56), ('코로나', 1.55), ('오늘', 1.44), ('다음에', 1.4), ('우리', 1.28), ('그다음에', 1.26), ('이제', 1.23), ('하는데', 1.22), ('지금부터', 1.2), ('여기', 1.15), ('저는', 1.14), ('지금은', 1.1), ('내가', 1.1), ('한번', 1.08), ('생각을', 1.07), ('해야 되겠네', 1.06), ('않겠나', 1.06), ('해야', 1.04), ('되겠네', 1.02), ('5월', 1.01), ('영향도', 0.97), ('만약에', 0.97)]\n"
     ]
    }
   ],
   "source": [
    "names = tf_vect.get_feature_names()\n",
    "\n",
    "topics = dict()\n",
    "\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "  vocab = []\n",
    "  for i in topic.argsort()[:-(30-1):-1]:\n",
    "    vocab.append((names[i], topic[i].round(2)))\n",
    "  print(\"topic %d: \" % (idx+1))\n",
    "\n",
    "  print([(names[i], topic[i].round(2)) for i in topic.argsort()[:-(30-1):-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEGhBHwwCh8f"
   },
   "outputs": [],
   "source": [
    "cnt_vect = CountVectorizer(ngram_range= (1,2), min_df = 2, max_df = 6000, max_features= 25000)\n",
    "dtm = cnt_vect.fit_transform(ex_sent)\n",
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components = n_topics , topic_word_prior= 0.01, doc_topic_prior = 0.001)\n",
    "lda.fit(dtm)\n",
    "saved_model = joblib.dump(dtm, 'LDA_0715prime_kss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPXfPEZUCh6R"
   },
   "outputs": [],
   "source": [
    "names = cnt_vect.get_feature_names()\n",
    "topics_word = dict()\n",
    "\n",
    "n_words = 10\n",
    "for idx, topic in enumerate (lda.components_):\n",
    "  #print(idx, topic)\n",
    "  vocab = []\n",
    "  for i in topic.argsort()[:-(n_words-1):-1]:\n",
    "    vocab.append((names[i], topic[i].round(2)))\n",
    "  topics_word[idx+1]= [(names[i], topic[i].round(2)) for i in topic.argsort()[:-(n_words-1):-1]]\n",
    "  max_dict = dict()\n",
    "for idx, vec in enumerate(lda.transform(dtm)):\n",
    "  t = vec.argmax()\n",
    "  if (t not in max_dict):\n",
    "    max_dict[t] = (vec[t], idx)\n",
    "  else:\n",
    "    if (max_dict[t][0]< vec[t]):\n",
    "      max_dict[t] = (vec[t], idx)\n",
    "\n",
    "sorted_review = sorted(max_dict.items(), key = lambda x: x[0], reverse = False)\n",
    "\n",
    "for key, value in sorted_review:\n",
    "  print('topic {}: {}'.format(key+1, topics_word[key+1]))\n",
    "  print('[주제 {}의 대표 문장: {}] \\n{}\\n\\n'.format(key+1, value[0], ex_sent[value[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jogx6odjKG7c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CnUTyP8Ch4B"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zDYJWEpCh2c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6V-MPjFICh0v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjzXazwOChy3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51UBvfYCChuu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
